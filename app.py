import os
os.environ["TORCH_ALLOW_TF32_CUDA"] = "0"  # Optional torch fix if using GPU

import streamlit as st
from corrector import correct_french
from qa_model import load_french_llm, answer_question

st.set_page_config(page_title="FranÃ§aisQA", page_icon="ğŸ‡«ğŸ‡·")

st.title("ğŸ‡«ğŸ‡· FranÃ§aisQA â€” Outil intelligent de correction et de rÃ©ponse en franÃ§ais")

tab1, tab2 = st.tabs(["ğŸ“ Correction de texte", "â“ Questions / RÃ©ponses"])

# --- Grammar Correction Tab ---
with tab1:
    st.subheader("Corrigez votre phrase en franÃ§ais")
    text_input = st.text_area("âœï¸ Entrez votre phrase ici :", height=150)
    
    if st.button("Corriger"):
        if not text_input.strip():
            st.warning("Veuillez entrer une phrase Ã  corriger.")
        else:
            corrected, explanations = correct_french(text_input)
            st.success(f"âœ… Phrase corrigÃ©e :\n\n{corrected}")
            if explanations:
                st.markdown("#### âœï¸ Explications :")
                for exp in explanations:
                    st.markdown(f"- **Erreur**: `{exp['error']}` â†’ **Message**: {exp['message']}")
                    if exp["suggestions"]:
                        st.markdown(f"  - **Suggestions**: {', '.join(exp['suggestions'])}")
            else:
                st.info("Aucune erreur dÃ©tectÃ©e.")

# --- Question Answering Tab ---
with tab2:
    st.subheader("Posez une question en franÃ§ais")
    user_question = st.text_input("â“ Votre question :")
    
    if st.button("RÃ©pondre"):
        if not user_question.strip():
            st.warning("Veuillez entrer une question.")
        else:
            with st.spinner("GÃ©nÃ©ration de la rÃ©ponse..."):
                pipe = load_french_llm()
                answer = answer_question(pipe, user_question)
                st.success(f"ğŸ’¬ RÃ©ponse : {answer}")
